<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pagina3 </title>
    <link rel="stylesheet" href="css/estilo.css">
</head>
<body>
    <header>
        <h3>institucion universitaria de barranquilla
        </h3>
        <br>
        <h3>Shadday Dennisse Ariza Viloria </h3>
    </header>
    <ul>
        <li><a href="../index.html">1</a></li>
        <li><a href="../2.html">2</a></li>
        <li><a href="">3</a></li>
        <li><a href="../4.html">4</a></li>
        <li><a href="../5.html">5</a></li>
        <li><a href="../Diario de fotos.html">Album</a></li>
        <li><a href="Sustentacion.html">Sustentacion</a></li>
        <li><a href="Animacion.html">Animacion</a></li>
    </ul>
    <h1>El auge de los modelos generativos
        La IA generativa</h1>
        <img src="img/Inteligencia-Artificial.jpg" width="1115">
        <p>se refiere a modelos de aprendizaje profundo que pueden tomar datos sin procesar; digamos, toda Wikipedia o los trabajos recopilados de Rembrandt, y “aprender” a generar resultados estadísticamente probables cuando se le solicite. En un alto nivel, los modelos generativos codifican una representación simplificada de sus datos de capacitación y los extraen para crear un nuevo trabajo similar, pero no idéntico, a los datos originales.
        </p>
        <p>
        Los modelos generativos se han utilizado durante años en estadísticas para analizar datos numéricos. Sin embargo, el auge del aprendizaje profundo permitió ampliarlos a imágenes, voz y otros tipos de datos complejos. Entre la primera clase de modelos que lograron esta hazaña cruzada se encuentran los autocodificadores variacionales, o VAE, introducidos en el 2013. Los VAE fueron los primeros modelos de aprendizaje profundo que se usaban ampliamente para generar imágenes y discursos realistas.
        </p>
        <p>
        “Los VAEs abrieron las puertas al modelado generativo profundo haciendo que los modelos sean más fáciles de escalar”, dijo Akash Srivastava, experto en IA generativa del MIT-IBM watsonx AI Lab. “Gran parte de lo que hoy pensamos como IA generativa comenzó aquí”.
        </p>
        <p>
        Los primeros ejemplos de modelos, como GPT-3, BERT o DALL-E 2, han demostrado lo que es posible. El futuro son modelos capacitados en un amplio conjunto de datos no etiquetados que se pueden utilizar para diferentes tareas, con un ajuste mínimo de precisión. Los sistemas que ejecutan tareas específicas en un solo dominio están dando paso a una IA amplia que aprende de manera más general y funciona en todos los dominios y problemas. Los modelos fundacionales, entrenados en grandes conjuntos de datos sin etiquetar y ajustados para una variedad de aplicaciones, están impulsando este cambio.
        </p>
        <p>
        Cuando se trata de IA generativa, se predice que el modelo fundacional acelerarán drásticamente la adopción de IA en la empresa. La reducción de los requisitos de etiquetado hará que sea mucho más fácil para las empresas sumergirse en ella, y la automatización altamente precisa y eficiente impulsada por la IA que permiten significará que muchas más empresas podrán desplegar la IA en una gama más amplia de situaciones de misión crítica. Para IBM, la esperanza es que el poder del modelo fundacional pueda eventualmente llevarse a todas las empresas en un entorno de nube híbrida sin fricciones.</p>
    <footer>sdriza@unibarranquilla.edu.co
        <br>
        Tel: 3022338361
    </footer>
</body>
</html>